# src/features/creator_agent/service/nodes/generate_quiz.py
from langchain_core.messages import AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from typing import List
from shared.llm import llm
from src.features.creator_agent.service.state import State


class QuizAnswer(BaseModel):
    answer_text: str = Field(description="Le texte de la r√©ponse")
    is_correct: bool = Field(description="Si cette r√©ponse est correcte")


class QuizQuestion(BaseModel):
    question_text: str = Field(description="Le texte de la question")
    question_type: str = Field(default="multiple_choice", description="Le type de question")
    explanation: str = Field(description="Explication de la bonne r√©ponse")
    answers: List[QuizAnswer] = Field(description="Liste des r√©ponses possibles")


class ModuleQuiz(BaseModel):
    title: str = Field(description="Titre du quiz")
    description: str = Field(description="Description du quiz")
    questions: List[QuizQuestion] = Field(description="Liste des questions du quiz")


def generate_quiz(state: State) -> State:
    """G√©n√®re un quiz pour un module apr√®s g√©n√©ration de toutes ses le√ßons"""
    
    # R√©cup√©rer le module actuel
    current_submodule = state.submodules[state.current_index]
    current_module_id = current_submodule["module_id"]
    
    # R√©cup√©rer toutes les le√ßons du module actuel
    current_module_lessons = []
    
    for sub in state.submodules:
        if sub["module_id"] == current_module_id:
            current_module_lessons.append({
                "title": sub["lesson_title"],
                "description": sub["lesson_description"],
                "content": state.outputs.get(sub["lesson_id"], "")
            })
    
    # Si on n'a pas de le√ßons, on skip
    if not current_module_lessons:
        return {"messages": [AIMessage(content="‚ùå Aucune le√ßon trouv√©e pour g√©n√©rer le quiz")]}
    
    # Cr√©er le parser pour la sortie structur√©e
    parser = PydanticOutputParser(pydantic_object=ModuleQuiz)
    
    # Template pour g√©n√©rer le quiz
    prompt = ChatPromptTemplate.from_template(
        """Tu es un expert en cr√©ation de quiz p√©dagogiques. 

Cr√©e un quiz de 5 questions √† choix multiples bas√© sur le contenu des le√ßons suivantes :

{lessons_content}

### Instructions pour le quiz :
1. G√©n√®re exactement 5 questions pertinentes
2. Chaque question doit avoir 4 r√©ponses possibles (A, B, C, D)
3. Une seule r√©ponse correcte par question
4. Inclus une explication pour chaque bonne r√©ponse
5. Les questions doivent couvrir les points cl√©s du module
6. Varie les types de questions (d√©finition, application, analyse)

### Titre du module : {module_title}

{format_instructions}
"""
    )
    
    # Pr√©parer le contenu des le√ßons
    lessons_text = ""
    for lesson in current_module_lessons:
        lessons_text += f"**{lesson['title']}**\n{lesson['description']}\n\n"
    
    # R√©cup√©rer le titre du module
    module_title = current_submodule.get("module_title", "Module")
    
    # Cr√©er la cha√Æne de traitement
    chain = prompt | llm | parser
    
    try:
        # G√©n√©rer le quiz
        quiz_data = chain.invoke({
            "lessons_content": lessons_text,
            "module_title": module_title,
            "format_instructions": parser.get_format_instructions()
        })
        
        # Stocker le quiz dans l'√©tat (s√©rialis√© en JSON)
        quiz_key = f"quiz_{current_module_id}"
        new_outputs = {**state.outputs, quiz_key: quiz_data.model_dump_json()}
        
        progress_msg = AIMessage(
            content=f"üìù Quiz g√©n√©r√© pour le module {current_module_id} ({len(quiz_data.questions)} questions)"
        )
        
        return {
            "messages": [progress_msg],
            "outputs": new_outputs
        }
        
    except Exception as e:
        error_msg = AIMessage(content=f"‚ùå Erreur lors de la g√©n√©ration du quiz: {str(e)}")
        return {"messages": [error_msg]}